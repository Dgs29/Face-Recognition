{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, Input, concatenate\n",
    "from keras.layers.pooling import MaxPool2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first') #Because our pretrained model uses channel first convention\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters : 3743280\n"
     ]
    }
   ],
   "source": [
    "FRmodel = faceRecoModel(input_shape = (3, 96, 96))\n",
    "print('Total parameters :',FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    '''y_pred --> list contains three objects\n",
    "    anchor -- shape : (None,128)\n",
    "    positive -- shape : (None, 128)\n",
    "    negative -- shape : (None , 128)\n",
    "    '''\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    #Encoding distance between anchor and positive\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1)\n",
    "    \n",
    "    #Encoding distance between anchor and negative\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1)\n",
    "    \n",
    "    #Subtract the two previous distances and add alpha.\n",
    "    difference = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    \n",
    "    #Finding the maximum between difference and 0. And summing over the entire training examples\n",
    "    loss = tf.reduce_sum(tf.maximum(difference, 0.0))\n",
    "    \n",
    "    return loss\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 528.1432\n"
     ]
    }
   ],
   "source": [
    "#To check, if function performs well\n",
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss(y_true, y_pred)\n",
    "    \n",
    "    print(\"loss = \" + str(loss.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the trained model\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping images to (3,96,96)\n",
    "path = 'images'\n",
    "for img in os.listdir(path):\n",
    "    img_array = cv2.imread(os.path.join(path,img))\n",
    "    new_array = cv2.resize(img_array,(96,96))\n",
    "    cv2.imwrite('modified_images/new_img_{}.jpg'.format(np.random.randint(1,1000)),new_array) #saving it to a new folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images can be converted to the required size using this way. Incase if you find the the converted images is of bad quality(in my case), you can reshape the image size manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a database to  store the names and its encodings\n",
    "database = {}\n",
    "database['Usain Bolt'] = img_to_encoding(\"images/bolt_96x96.jpg\",FRmodel)\n",
    "database['Cristiano Ronaldo'] = img_to_encoding(\"images/cristiano_1_96x96.jpg\",FRmodel)\n",
    "database['Lewis Hamilton'] = img_to_encoding(\"images/hamilton_96x96.jpg\",FRmodel)\n",
    "database['Virat Kohli'] = img_to_encoding(\"images/kohli_1_96x96.jpg\",FRmodel)\n",
    "database['Lionel Messi'] = img_to_encoding(\"images/messi_2_96x96.jpg\",FRmodel)\n",
    "database['Elon Musk'] = img_to_encoding(\"images/elon_96x96.png\",FRmodel)\n",
    "database['Jeff Bezos'] = img_to_encoding(\"images/jeff_96x96.jpg\",FRmodel)\n",
    "database['Robert Downey Jr'] = img_to_encoding(\"images/rdj_3_96x96.jpg\",FRmodel)\n",
    "database['Tom Cruise'] = img_to_encoding(\"images/tom_1_96x96.jpg\",FRmodel)\n",
    "database['Narendra Modi'] = img_to_encoding(\"images/modi_1_96x96.jpg\",FRmodel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "    #Compute the encoding of the image\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    \n",
    "    #Compute distance with identity's image\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "    \n",
    "    if dist < 0.65:\n",
    "        print(\"Hey! \" +str(identity)+\", welcome to the party\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \"+str(identity)+\" please go away\")\n",
    "        door_open = False\n",
    "        \n",
    "    return dist, door_open\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Cristiano Ronaldo, welcome to the party\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6072807, True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify('test_images/ronaldo_96x96.jpg', 'Cristiano Ronaldo', database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not Virat Kohli please go away\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.68979377, False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify('test_images/trump_96x96.jpg', 'Virat Kohli', database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise(image_path, database, model):\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    min_dist = 100\n",
    "    \n",
    "    for (name, db_enc) in database.items():\n",
    "        dist = np.linalg.norm(encoding - db_enc)\n",
    "        \n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "            \n",
    "    if min_dist > 0.65:\n",
    "        print('Not in the database')\n",
    "    else:\n",
    "        print(\"It's \"+str(identity)+\", the distance is \"+str(min_dist))\n",
    "            \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in the database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.68979377, 'Virat Kohli')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognise('test_images/trump_96x96.jpg', database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's Usain Bolt, the distance is 0.4575208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4575208, 'Usain Bolt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognise('test_images/bolt_4_96x96.jpg', database, FRmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
